{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import GradientBoostingRegressor, StackingRegressor\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import joblib\n"
      ],
      "metadata": {
        "id": "jWYaUOFd5QKt"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(filepath: str) -> pd.DataFrame:\n",
        "    \"\"\"Loading and returning the raw CSV data.\"\"\"\n",
        "    return pd.read_csv(filepath, encoding='latin1')\n",
        "\n",
        "def inspect_data(df: pd.DataFrame):\n",
        "    \"\"\"Printing head(), info(), and describe().\"\"\"\n",
        "    print(df.head(), \"\\n\")\n",
        "    df.info(); print(\"\\n\")\n",
        "    print(df.describe(), \"\\n\")\n",
        "\n",
        "def plot_eda(df: pd.DataFrame):\n",
        "    \"\"\"Simple EDA: scatter and heatmap for key features.\"\"\"\n",
        "    sns.pairplot(df, vars=['annual Salary','credit card debt','net worth'],\n",
        "                 y_vars=['car purchase amount'])\n",
        "    plt.suptitle(\"Feature vs. Target\")\n",
        "    plt.show()\n",
        "    plt.figure(figsize=(6,5))\n",
        "    sns.heatmap(df.corr(), annot=True)\n",
        "    plt.title(\"Correlation Matrix\")\n",
        "    plt.show()\n",
        "\n",
        "def preprocess_and_engineer(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Impute, scale, and add polynomial & categorical features.\"\"\"\n",
        "    # Column definitions\n",
        "    num_cols = ['age','annual Salary','credit card debt','net worth']\n",
        "    cat_cols = ['country','gender']\n",
        "\n",
        "    # Building transformer\n",
        "    preprocessor = ColumnTransformer([\n",
        "        ('num', Pipeline([\n",
        "            ('impute', SimpleImputer(strategy='median')),\n",
        "            ('scale', StandardScaler()),\n",
        "            ('poly', PolynomialFeatures(degree=2, include_bias=False))\n",
        "        ]), num_cols),\n",
        "        ('cat', Pipeline([\n",
        "            ('impute', SimpleImputer(strategy='most_frequent')),\n",
        "            ('onehot',\n",
        "             # handling unknowns gracefully\n",
        "             # drop='first' to avoid multicollinearity\n",
        "             SimpleImputer(strategy='most_frequent')\n",
        "\n",
        "            )\n",
        "        ]), cat_cols)\n",
        "    ], remainder='drop')\n",
        "\n",
        "    features = preprocessor.fit_transform(df)\n",
        "    return features\n",
        "\n",
        "def train_and_evaluate(X, y):\n",
        "    \"\"\"Split data, train a stacking regressor, and print metrics.\"\"\"\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42\n",
        "    )\n",
        "    # Ensemble of Linear + Gradient Boosting\n",
        "    stack = StackingRegressor(\n",
        "        estimators=[('lr', LinearRegression()),\n",
        "                    ('gb', GradientBoostingRegressor(random_state=42))],\n",
        "        final_estimator=GradientBoostingRegressor(n_estimators=50, random_state=42),\n",
        "        cv=5\n",
        "    )\n",
        "    pipeline = Pipeline([('model', stack)])\n",
        "\n",
        "    # Hyperparameter tuning\n",
        "    param_dist = {\n",
        "        'model__final_estimator__learning_rate': [0.01, 0.1],\n",
        "        'model__final_estimator__n_estimators': [100, 200]\n",
        "    }\n",
        "    search = RandomizedSearchCV(pipeline, param_dist, n_iter=4, cv=3,\n",
        "                                scoring='neg_root_mean_squared_error',\n",
        "                                random_state=42)\n",
        "    search.fit(X_train, y_train)\n",
        "\n",
        "    best = search.best_estimator_\n",
        "    preds = best.predict(X_test)\n",
        "    rmse = mean_squared_error(y_test, preds, squared=False)\n",
        "    r2   = r2_score(y_test, preds)\n",
        "    print(f\"Test RMSE: {rmse:.2f}, R²: {r2:.3f}\")\n",
        "\n",
        "    # Saving the model\n",
        "    joblib.dump(best, \"sales_model.pkl\")\n"
      ],
      "metadata": {
        "id": "g-BNrMDp5RMp"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # 1. Loading\n",
        "    df = pd.read_csv(\"car_purchasing.csv\", encoding='latin1')\n",
        "\n",
        "    # 2. Preparing X, y\n",
        "    # — drop name/email, one-hot encode country\n",
        "    df = pd.get_dummies(df, columns=['country'], drop_first=True)\n",
        "    feature_cols = [c for c in df.columns\n",
        "                    if c not in ['customer name', 'customer e-mail', 'car purchase amount']]\n",
        "    X = df[feature_cols].values\n",
        "    y = df['car purchase amount'].values\n",
        "\n",
        "    # 3. Train/test split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # 4. Build & fit model\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    model = LinearRegression()\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "\n",
        "    # 5. Evaluate\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "    preds = model.predict(X_test_scaled)\n",
        "    print(\"MAE:\", mean_squared_error(y_test, preds))\n",
        "    print(\"R²:\", r2_score(y_test, preds))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMv3dWng5WjD",
        "outputId": "012201c1-a05c-46c5-fa2b-d0bcf82fba8b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE: 2.8176137271814223\n",
            "R²: 0.9999999739044987\n"
          ]
        }
      ]
    }
  ]
}